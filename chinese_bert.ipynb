{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOPy2wzk1VN+GgfFS25ikIZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/woo1027/chinese_bert/blob/main/chinese_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T--kSUgWJhLd"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import IPython\n",
        "from google.colab import output\n",
        "\n",
        "display(IPython.display.Javascript('''\n",
        " function ClickConnect(){\n",
        "   btn = document.querySelector(\"colab-connect-button\")\n",
        "   if (btn != null){\n",
        "     console.log(\"Click colab-connect-button\");\n",
        "     btn.click()\n",
        "     }\n",
        "\n",
        "   btn = document.getElementById('ok')\n",
        "   if (btn != null){\n",
        "     console.log(\"Click reconnect\");\n",
        "     btn.click()\n",
        "     }\n",
        "  }\n",
        "\n",
        "setInterval(ClickConnect,60000)\n",
        "'''))\n",
        "\n",
        "print(\"Done.\")\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "z9nGu1_cJ4jq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "toxic = pd.read_csv(\"/content/drive/My Drive//toxic.csv\")\n",
        "toxic.head()"
      ],
      "metadata": {
        "id": "-OsZfuXOJyAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"訓練集遺失值：\\n{}\".format(toxic.isnull().sum()))"
      ],
      "metadata": {
        "id": "5buKAbi3J9Ir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "toxic = toxic.dropna(axis=0)\n"
      ],
      "metadata": {
        "id": "cRmiOFWnJyBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newdata = toxic.drop(columns=['Unnamed: 0'])\n",
        "newdata"
      ],
      "metadata": {
        "id": "K7oBABvHKt5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "clean_com_chinese欄位 為 翻譯成中文的評論"
      ],
      "metadata": {
        "id": "jizVuDeJKtgf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_stats = newdata[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum()\n",
        "print(label_stats)\n",
        "\n",
        "comments=newdata['clean_com_chinese'].to_list()\n",
        "comments[:5]"
      ],
      "metadata": {
        "id": "mr-y5z72K9EL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "j71oArxVK9DI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training, testing sets & validation sets\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(\n",
        "    comments, newdata.iloc[:,2:8].values, test_size=0.3, random_state=1)\n",
        "\n",
        "#validation set\n",
        "test_data, val_data, test_labels, val_labels = train_test_split(\n",
        "    test_data, test_labels, test_size=0.67, random_state=1)\n",
        "\n",
        "print('numbers of training Dataset ',len(train_data))\n",
        "print('numbers of testing Dataset',len(test_data))\n",
        "print('numbers of validation Dataset',len(val_data))"
      ],
      "metadata": {
        "id": "PSLUJapmK892"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_and_encode(tokenizer, comments, labels, max_length=128):\n",
        "    # Initialize empty lists to store tokenized inputs and attention masks\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    # Iterate through each comment in the 'comments' list\n",
        "    for comment in comments:\n",
        "        # Tokenize and encode the comment using the BERT tokenizer\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "            comment,\n",
        "            add_special_tokens=True,\n",
        "            max_length=max_length,\n",
        "            pad_to_max_length=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        # Append the tokenized input and attention mask to their respective lists\n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    # Convert the lists of tokenized inputs and attention masks to PyTorch tensors\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "    # Convert the labels to a PyTorch tensor with the data type float32\n",
        "    labels = torch.tensor(labels, dtype=torch.float32)\n",
        "\n",
        "    # Return the tokenized inputs, attention masks, and labels as PyTorch tensors\n",
        "    return input_ids, attention_masks, labels"
      ],
      "metadata": {
        "id": "vHPTbqK9K885"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ],
      "metadata": {
        "id": "b73kv40zLZhs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Token Initialization\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese', do_lower_case=True)\n",
        "\n",
        "# Model Initialization\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-chinese', num_labels=6)"
      ],
      "metadata": {
        "id": "kQsDRfTTJyGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Move model to GPU if available\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(device)\n",
        "\n",
        "model =model.to(device)"
      ],
      "metadata": {
        "id": "izdzqrpgK8xg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize and Encode the comments and labels for the training set\n",
        "input_ids, attention_masks, labels = tokenize_and_encode(\n",
        "    tokenizer,\n",
        "    train_data,\n",
        "    train_labels\n",
        ")\n",
        "\n",
        "# Step 4: Tokenize and Encode the comments and labels for the test set\n",
        "test_input_ids, test_attention_masks, test_labels = tokenize_and_encode(\n",
        "    tokenizer,\n",
        "    test_data,\n",
        "    test_labels\n",
        ")\n",
        "\n",
        "# Tokenize and Encode the comments and labels for the validation set\n",
        "val_input_ids, val_attention_masks, val_labels = tokenize_and_encode(\n",
        "    tokenizer,\n",
        "    val_data,\n",
        "    val_labels\n",
        ")"
      ],
      "metadata": {
        "id": "O4TAGq5SLhRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating DataLoader for the balanced dataset\n",
        "batch_size = 32\n",
        "train_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "#test\n",
        "test_dataset = TensorDataset(test_input_ids, test_attention_masks, test_labels)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "#val\n",
        "val_dataset = TensorDataset(val_input_ids, val_attention_masks, val_labels)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "JElzumUdQygC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ljyEMoZ8Ncdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the tokenizer and model from the saved directory\n",
        "model_name =\"/content/drive/My Drive/Saved_model\"\n",
        "Bert_Tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "Bert_Model = BertForSequenceClassification.from_pretrained(model_name).to(device)"
      ],
      "metadata": {
        "id": "s8YMTUPHNcwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_user_input(input_text, model=Bert_Model, tokenizer=Bert_Tokenizer,device=device):\n",
        "    user_input = [input_text]\n",
        "\n",
        "    user_encodings = tokenizer(user_input, truncation=True, padding=True, return_tensors=\"pt\")\n",
        "\n",
        "    user_dataset = TensorDataset(user_encodings['input_ids'], user_encodings['attention_mask'])\n",
        "\n",
        "    user_loader = DataLoader(user_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in user_loader:\n",
        "            input_ids, attention_mask = [t.to(device) for t in batch]\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits\n",
        "            predictions = torch.sigmoid(logits)\n",
        "    predicted_labels = (predictions.cpu().numpy() > 0.5).astype(int)\n",
        "    return predicted_labels[0].tolist()"
      ],
      "metadata": {
        "id": "M9F3yG9ONi0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = '你是智障嗎?'\n",
        "predict_user_input(input_text=text)"
      ],
      "metadata": {
        "id": "8EILhRgfNcxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "有毒的、嚴重有毒、猥褻、威脅、侮辱、身分仇恨"
      ],
      "metadata": {
        "id": "IcG7xaZjRZi3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"你真的很討厭，但我愛你\"\n",
        "predict_user_input(model=Bert_Model,\n",
        "                   tokenizer=Bert_Tokenizer,\n",
        "                   input_text=text,\n",
        "                   device=device)"
      ],
      "metadata": {
        "id": "1-_tvVJdRYQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "有毒的、嚴重有毒、猥褻、威脅、侮辱、身分仇恨"
      ],
      "metadata": {
        "id": "DPeNF1oxU6AQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = '你這個婊子'\n",
        "predict_user_input(input_text)"
      ],
      "metadata": {
        "id": "oB6F2pX-Ru61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "有毒的、嚴重有毒、猥褻、威脅、侮辱、身分仇恨"
      ],
      "metadata": {
        "id": "ny21xcKuVBoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"閉嘴，笨蛋\"\n",
        "predict_user_input(model=Bert_Model,\n",
        "                   tokenizer=Bert_Tokenizer,\n",
        "                   input_text=text,\n",
        "                   device=device)"
      ],
      "metadata": {
        "id": "q2fkavxqRspd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "有毒的、嚴重有毒、猥褻、威脅、侮辱、身分仇恨"
      ],
      "metadata": {
        "id": "Qga9coXyVCei"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask flask-ngrok\n"
      ],
      "metadata": {
        "id": "-XCjR6dqR1b4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, render_template_string\n",
        "from flask_ngrok import run_with_ngrok\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ],
      "metadata": {
        "id": "lRv9xsXdVKMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkza3eWbnE85",
        "outputId": "8cd353d5-d82e-433b-b912-36805acbe171"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "Exception in thread Thread-10:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\", line 198, in _new_conn\n",
            "    sock = connection.create_connection(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/util/connection.py\", line 85, in create_connection\n",
            "    raise err\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/util/connection.py\", line 73, in create_connection\n",
            "    sock.connect(sa)\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
            "    response = self._make_request(\n",
            "               ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\", line 493, in _make_request\n",
            "    conn.request(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\", line 445, in request\n",
            "    self.endheaders()\n",
            "  File \"/usr/lib/python3.11/http/client.py\", line 1298, in endheaders\n",
            "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
            "  File \"/usr/lib/python3.11/http/client.py\", line 1058, in _send_output\n",
            "    self.send(msg)\n",
            "  File \"/usr/lib/python3.11/http/client.py\", line 996, in send\n",
            "    self.connect()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\", line 276, in connect\n",
            "    self.sock = self._new_conn()\n",
            "                ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\", line 213, in _new_conn\n",
            "    raise NewConnectionError(\n",
            "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7a2f5169fc10>: Failed to establish a new connection: [Errno 111] Connection refused\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/requests/adapters.py\", line 667, in send\n",
            "    resp = conn.urlopen(\n",
            "           ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\", line 841, in urlopen\n",
            "    retries = retries.increment(\n",
            "              ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/util/retry.py\", line 519, in increment\n",
            "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=4040): Max retries exceeded with url: /api/tunnels (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7a2f5169fc10>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1401, in run\n",
            "    self.function(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flask_ngrok.py\", line 70, in start_ngrok\n",
            "    ngrok_address = _run_ngrok()\n",
            "                    ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flask_ngrok.py\", line 35, in _run_ngrok\n",
            "    tunnel_url = requests.get(localhost_url).text  # Get the tunnel information\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/requests/api.py\", line 73, in get\n",
            "    return request(\"get\", url, params=params, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/requests/api.py\", line 59, in request\n",
            "    return session.request(method=method, url=url, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/requests/sessions.py\", line 589, in request\n",
            "    resp = self.send(prep, **send_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/requests/sessions.py\", line 703, in send\n",
            "    r = adapter.send(request, **kwargs)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/requests/adapters.py\", line 700, in send\n",
            "    raise ConnectionError(e, request=request)\n",
            "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=4040): Max retries exceeded with url: /api/tunnels (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7a2f5169fc10>: Failed to establish a new connection: [Errno 111] Connection refused'))\n"
          ]
        }
      ],
      "source": [
        "# Flask app 初始化\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)\n",
        "\n",
        "# 你的模型與 tokenizer 路徑\n",
        "model_path = \"/content/drive/My Drive/Saved_model\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 載入模型與 tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
        "model = BertForSequenceClassification.from_pretrained(model_path).to(device)\n",
        "model.eval()\n",
        "\n",
        "labels = [\"有毒的\", \"嚴重有毒\", \"猥褻\", \"威脅\", \"侮辱\", \"身分仇恨\"]\n",
        "\n",
        "def predict_user_input(input_text):\n",
        "    encodings = tokenizer([input_text], truncation=True, padding=True, return_tensors=\"pt\")\n",
        "    input_ids = encodings['input_ids'].to(device)\n",
        "    attention_mask = encodings['attention_mask'].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        predictions = torch.sigmoid(logits)\n",
        "\n",
        "    predicted_labels = (predictions.cpu().numpy() > 0.5).astype(int)[0].tolist()\n",
        "    return list(zip(labels, predicted_labels))\n",
        "\n",
        "\n",
        "# HTML 前端模板\n",
        "html_template = '''\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head><meta charset=\"UTF-8\"><title>毒性分析系統</title></head>\n",
        "<body>\n",
        "    <h2>請輸入評論：</h2>\n",
        "    <form method=\"post\">\n",
        "        <textarea name=\"comment\" rows=\"4\" cols=\"50\">{{ user_input }}</textarea><br><br>\n",
        "        <input type=\"submit\" value=\"送出分析\">\n",
        "    </form>\n",
        "    {% if result %}\n",
        "        <h3>預測結果：</h3>\n",
        "        <ul>\n",
        "        {% for label, val in result %}\n",
        "            <li>{{ label }}：{{ '✔️' if val == 1 else '❌' }}</li>\n",
        "        {% endfor %}\n",
        "        </ul>\n",
        "    {% endif %}\n",
        "</body>\n",
        "</html>\n",
        "'''\n",
        "\n",
        "# 路由\n",
        "@app.route(\"/\", methods=[\"GET\", \"POST\"])\n",
        "def index():\n",
        "    result = None\n",
        "    user_input = \"\"\n",
        "    if request.method == \"POST\":\n",
        "        user_input = request.form[\"comment\"]\n",
        "        result = predict_user_input(user_input)\n",
        "    return render_template_string(html_template, result=result, user_input=user_input)\n",
        "\n",
        "# 啟動 app\n",
        "app.run()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "23PN47HIVP8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bK99fAFzVQY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "38IYZ2q0VTsV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}