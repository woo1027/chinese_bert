{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPcVhu3ua9ytR8Dp3DAmBxl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/woo1027/project/blob/bert/chinese_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T--kSUgWJhLd"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import IPython\n",
        "from google.colab import output\n",
        "\n",
        "display(IPython.display.Javascript('''\n",
        " function ClickConnect(){\n",
        "   btn = document.querySelector(\"colab-connect-button\")\n",
        "   if (btn != null){\n",
        "     console.log(\"Click colab-connect-button\");\n",
        "     btn.click()\n",
        "     }\n",
        "\n",
        "   btn = document.getElementById('ok')\n",
        "   if (btn != null){\n",
        "     console.log(\"Click reconnect\");\n",
        "     btn.click()\n",
        "     }\n",
        "  }\n",
        "\n",
        "setInterval(ClickConnect,60000)\n",
        "'''))\n",
        "\n",
        "print(\"Done.\")\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "z9nGu1_cJ4jq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "toxic = pd.read_csv(\"/content/drive/My Drive//toxic.csv\")\n",
        "toxic.head()"
      ],
      "metadata": {
        "id": "-OsZfuXOJyAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"è¨“ç·´é›†éºå¤±å€¼ï¼š\\n{}\".format(toxic.isnull().sum()))"
      ],
      "metadata": {
        "id": "5buKAbi3J9Ir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "toxic = toxic.dropna(axis=0)\n"
      ],
      "metadata": {
        "id": "cRmiOFWnJyBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newdata = toxic.drop(columns=['Unnamed: 0'])\n",
        "newdata"
      ],
      "metadata": {
        "id": "K7oBABvHKt5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "clean_com_chineseæ¬„ä½ ç‚º ç¿»è­¯æˆä¸­æ–‡çš„è©•è«–"
      ],
      "metadata": {
        "id": "jizVuDeJKtgf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_stats = newdata[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum()\n",
        "print(label_stats)\n",
        "\n",
        "comments=newdata['clean_com_chinese'].to_list()\n",
        "comments[:5]"
      ],
      "metadata": {
        "id": "mr-y5z72K9EL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "j71oArxVK9DI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training, testing sets & validation sets\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(\n",
        "    comments, newdata.iloc[:,2:8].values, test_size=0.3, random_state=1)\n",
        "\n",
        "#validation set\n",
        "test_data, val_data, test_labels, val_labels = train_test_split(\n",
        "    test_data, test_labels, test_size=0.67, random_state=1)\n",
        "\n",
        "print('numbers of training Dataset ',len(train_data))\n",
        "print('numbers of testing Dataset',len(test_data))\n",
        "print('numbers of validation Dataset',len(val_data))"
      ],
      "metadata": {
        "id": "PSLUJapmK892"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_and_encode(tokenizer, comments, labels, max_length=128):\n",
        "    # Initialize empty lists to store tokenized inputs and attention masks\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    # Iterate through each comment in the 'comments' list\n",
        "    for comment in comments:\n",
        "        # Tokenize and encode the comment using the BERT tokenizer\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "            comment,\n",
        "            add_special_tokens=True,\n",
        "            max_length=max_length,\n",
        "            pad_to_max_length=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        # Append the tokenized input and attention mask to their respective lists\n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    # Convert the lists of tokenized inputs and attention masks to PyTorch tensors\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "    # Convert the labels to a PyTorch tensor with the data type float32\n",
        "    labels = torch.tensor(labels, dtype=torch.float32)\n",
        "\n",
        "    # Return the tokenized inputs, attention masks, and labels as PyTorch tensors\n",
        "    return input_ids, attention_masks, labels"
      ],
      "metadata": {
        "id": "vHPTbqK9K885"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ],
      "metadata": {
        "id": "b73kv40zLZhs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Token Initialization\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese', do_lower_case=True)\n",
        "\n",
        "# Model Initialization\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-chinese', num_labels=6)"
      ],
      "metadata": {
        "id": "kQsDRfTTJyGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Move model to GPU if available\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(device)\n",
        "\n",
        "model =model.to(device)"
      ],
      "metadata": {
        "id": "izdzqrpgK8xg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize and Encode the comments and labels for the training set\n",
        "input_ids, attention_masks, labels = tokenize_and_encode(\n",
        "    tokenizer,\n",
        "    train_data,\n",
        "    train_labels\n",
        ")\n",
        "\n",
        "# Step 4: Tokenize and Encode the comments and labels for the test set\n",
        "test_input_ids, test_attention_masks, test_labels = tokenize_and_encode(\n",
        "    tokenizer,\n",
        "    test_data,\n",
        "    test_labels\n",
        ")\n",
        "\n",
        "# Tokenize and Encode the comments and labels for the validation set\n",
        "val_input_ids, val_attention_masks, val_labels = tokenize_and_encode(\n",
        "    tokenizer,\n",
        "    val_data,\n",
        "    val_labels\n",
        ")"
      ],
      "metadata": {
        "id": "O4TAGq5SLhRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating DataLoader for the balanced dataset\n",
        "batch_size = 32\n",
        "train_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "#test\n",
        "test_dataset = TensorDataset(test_input_ids, test_attention_masks, test_labels)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "#val\n",
        "val_dataset = TensorDataset(val_input_ids, val_attention_masks, val_labels)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "JElzumUdQygC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ljyEMoZ8Ncdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the tokenizer and model from the saved directory\n",
        "model_name =\"/content/drive/My Drive/Saved_model\"\n",
        "Bert_Tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "Bert_Model = BertForSequenceClassification.from_pretrained(model_name).to(device)"
      ],
      "metadata": {
        "id": "s8YMTUPHNcwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_user_input(input_text, model=Bert_Model, tokenizer=Bert_Tokenizer,device=device):\n",
        "    user_input = [input_text]\n",
        "\n",
        "    user_encodings = tokenizer(user_input, truncation=True, padding=True, return_tensors=\"pt\")\n",
        "\n",
        "    user_dataset = TensorDataset(user_encodings['input_ids'], user_encodings['attention_mask'])\n",
        "\n",
        "    user_loader = DataLoader(user_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in user_loader:\n",
        "            input_ids, attention_mask = [t.to(device) for t in batch]\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits\n",
        "            predictions = torch.sigmoid(logits)\n",
        "    predicted_labels = (predictions.cpu().numpy() > 0.5).astype(int)\n",
        "    return predicted_labels[0].tolist()"
      ],
      "metadata": {
        "id": "M9F3yG9ONi0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'ä½ é€™å€‹æ™ºéšœå—?'\n",
        "predict_user_input(input_text=text)"
      ],
      "metadata": {
        "id": "8EILhRgfNcxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "æœ‰æ¯’çš„ã€åš´é‡æœ‰æ¯’ã€çŒ¥è¤»ã€å¨è„…ã€ä¾®è¾±ã€èº«åˆ†ä»‡æ¨"
      ],
      "metadata": {
        "id": "IcG7xaZjRZi3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"ä½ çœŸçš„å¾ˆç¬¨ï¼Œä½†æˆ‘æ„›ä½ \"\n",
        "predict_user_input(model=Bert_Model,\n",
        "                   tokenizer=Bert_Tokenizer,\n",
        "                   input_text=text,\n",
        "                   device=device)"
      ],
      "metadata": {
        "id": "1-_tvVJdRYQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "æœ‰æ¯’çš„ã€åš´é‡æœ‰æ¯’ã€çŒ¥è¤»ã€å¨è„…ã€ä¾®è¾±ã€èº«åˆ†ä»‡æ¨"
      ],
      "metadata": {
        "id": "DPeNF1oxU6AQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = 'ä½ é€™å€‹å©Šå­'\n",
        "predict_user_input(input_text)"
      ],
      "metadata": {
        "id": "oB6F2pX-Ru61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "æœ‰æ¯’çš„ã€åš´é‡æœ‰æ¯’ã€çŒ¥è¤»ã€å¨è„…ã€ä¾®è¾±ã€èº«åˆ†ä»‡æ¨"
      ],
      "metadata": {
        "id": "ny21xcKuVBoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"é–‰å˜´ï¼Œç¬¨è›‹\"\n",
        "predict_user_input(model=Bert_Model,\n",
        "                   tokenizer=Bert_Tokenizer,\n",
        "                   input_text=text,\n",
        "                   device=device)"
      ],
      "metadata": {
        "id": "q2fkavxqRspd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "æœ‰æ¯’çš„ã€åš´é‡æœ‰æ¯’ã€çŒ¥è¤»ã€å¨è„…ã€ä¾®è¾±ã€èº«åˆ†ä»‡æ¨"
      ],
      "metadata": {
        "id": "Qga9coXyVCei"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# å®‰è£å¿…è¦å¥—ä»¶\n",
        "!pip install flask pyngrok transformers torch"
      ],
      "metadata": {
        "id": "-XCjR6dqR1b4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, render_template_string\n",
        "from flask_ngrok import run_with_ngrok\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ],
      "metadata": {
        "id": "lRv9xsXdVKMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "23PN47HIVP8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, render_template_string\n",
        "from pyngrok import ngrok\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from threading import Thread\n"
      ],
      "metadata": {
        "id": "kMbySY_VyvyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# ç”¨ä½ çš„ authtoken æ›¿æ›ä¸‹é¢é€™ä¸€è¡Œå­—ä¸²\n",
        "ngrok.set_auth_token(\"2wrCNRhYSAU6fxDhgmhvn0l2oPZ_4i2UHNMkDkXqYKzsRMSMU\")\n"
      ],
      "metadata": {
        "id": "38IYZ2q0VTsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ğŸ“ æ¨¡å‹èˆ‡ tokenizer è·¯å¾‘ï¼ˆé€™æ˜¯ä½ åœ¨ Google Drive ä¸­çš„å„²å­˜ä½ç½®ï¼‰\n",
        "model_path = \"/content/drive/My Drive/Saved_model\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# â¬ è¼‰å…¥æ¨¡å‹èˆ‡ tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
        "model = BertForSequenceClassification.from_pretrained(model_path).to(device)\n",
        "model.eval()\n",
        "\n",
        "labels = [\"æœ‰æ¯’çš„\", \"åš´é‡æœ‰æ¯’\", \"çŒ¥è¤»\", \"å¨è„…\", \"ä¾®è¾±\", \"èº«åˆ†ä»‡æ¨\"]\n",
        "\n",
        "\n",
        "\n",
        "# ğŸ” é æ¸¬å‡½å¼\n",
        "def predict_user_input(input_text):\n",
        "    encodings = tokenizer([input_text], truncation=True, padding=True, return_tensors=\"pt\")\n",
        "    input_ids = encodings['input_ids'].to(device)\n",
        "    attention_mask = encodings['attention_mask'].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        predictions = torch.sigmoid(logits)\n",
        "\n",
        "    predicted_labels = (predictions.cpu().numpy() > 0.5).astype(int)[0].tolist()\n",
        "    return list(zip(labels, predicted_labels))\n",
        "\n",
        "\n",
        "\n",
        "# å»ºç«‹ Flask æ‡‰ç”¨\n",
        "app = Flask(__name__)\n",
        "\n",
        "\n",
        "# ğŸŒ HTML æ¨¡æ¿\n",
        "html_template = '''\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head><meta charset=\"UTF-8\"><title>æ¯’æ€§åˆ†æç³»çµ±</title></head>\n",
        "<body>\n",
        "    <h2>è«‹è¼¸å…¥è©•è«–ï¼š</h2>\n",
        "    <form method=\"post\">\n",
        "        <textarea name=\"comment\" rows=\"4\" cols=\"50\">{{ user_input }}</textarea><br><br>\n",
        "        <input type=\"submit\" value=\"é€å‡ºåˆ†æ\">\n",
        "    </form>\n",
        "    {% if result %}\n",
        "        <h3>åˆ†æçµæœï¼š</h3>\n",
        "        <ul>\n",
        "        {% for label, val in result %}\n",
        "            <li>{{ label }}ï¼š{{ 'âœ”ï¸' if val == 1 else 'âŒ' }}</li>\n",
        "        {% endfor %}\n",
        "        </ul>\n",
        "    {% endif %}\n",
        "</body>\n",
        "</html>\n",
        "'''\n",
        "\n",
        "# ğŸšª è·¯ç”±è¨­å®š\n",
        "@app.route(\"/\", methods=[\"GET\", \"POST\"])\n",
        "def index():\n",
        "    result = None\n",
        "    user_input = \"\"\n",
        "    if request.method == \"POST\":\n",
        "        user_input = request.form[\"comment\"]\n",
        "        result = predict_user_input(user_input)\n",
        "    return render_template_string(html_template, result=result, user_input=user_input)\n",
        "\n",
        "# å•Ÿå‹• Flask åœ¨èƒŒæ™¯é‹è¡Œï¼ˆä½¿ç”¨ Threadï¼‰\n",
        "def run_app():\n",
        "    app.run(port=5000)"
      ],
      "metadata": {
        "id": "kwopngFr0-Ja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# å»ºç«‹ ngrok å…¬é–‹ç¶²å€\n",
        "public_url = ngrok.connect(5000)\n",
        "print(f\"ğŸš€ è«‹é»æ­¤é–‹å•Ÿæ‡‰ç”¨ç¨‹å¼ï¼š{public_url}\")\n",
        "\n",
        "# å•Ÿå‹• Flask\n",
        "Thread(target=run_app).start()"
      ],
      "metadata": {
        "id": "nMdFjASz01If"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E0d0FSdcrGNx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}