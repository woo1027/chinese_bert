import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import mean_squared_error, r2_score
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import itertools


# ä¸­æ–‡å­—é«”è¨­å®šï¼ˆå¦‚éœ€ï¼‰
plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei']
plt.rcParams['axes.unicode_minus'] = False

# è®€å–è³‡æ–™
game = pd.read_csv("D:/é¢è©¦è³‡æ–™/R/vgsales_utf8.csv", encoding="utf-8")

# æ¬„ä½å‘½å
game.columns = ['æ’å', 'éŠæˆ²åç¨±', 'å¹³å°', 'ç™¼è¡Œå¹´ä»½', 'éŠæˆ²é¡å‹', 'ç™¼è¡Œå•†',
                'åŒ—ç¾éŠ·å”®é¡', 'æ­æ´²éŠ·å”®é¡', 'æ—¥æœ¬éŠ·å”®é¡', 'å…¶ä»–åœ°å€éŠ·å”®é¡', 'ç¸½éŠ·å”®é¡']

# ç§»é™¤"æ’å"æ¬„
game = game.drop(columns=['æ’å'])

# æŸ¥çœ‹æ¬„ä½æ˜¯å¦æœ‰ "N/A"
for col in game.columns:
    na_count = (game[col] == "N/A").sum()
    if na_count > 0:
        print(f"æ¬„ä½ {col} æœ‰ {na_count} å€‹ \"N/A\"")


# é¡¯ç¤ºç¼ºå¤±å€¼æ•¸é‡
print(game.isna().sum())

# # å°‡å¹´ä»½è½‰ç‚ºæ•¸å­—
# game['ç™¼è¡Œå¹´ä»½'] = pd.to_numeric(game['ç™¼è¡Œå¹´ä»½'], errors='coerce')

game['ç™¼è¡Œå¹´ä»½'] = pd.to_numeric(game['ç™¼è¡Œå¹´ä»½'], errors='coerce')
game['ç¸½éŠ·å”®é¡'] = pd.to_numeric(game['ç¸½éŠ·å”®é¡'], errors='coerce')
game.dropna(subset=['ç™¼è¡Œå¹´ä»½', 'ç¸½éŠ·å”®é¡'], inplace=True)
#
#
# # é¡åˆ¥ç‰¹å¾µè½‰æ›
# label_cols = ['å¹³å°', 'éŠæˆ²é¡å‹', 'ç™¼è¡Œå•†']
# for col in label_cols:
#     game[col] = LabelEncoder().fit_transform(game[col].astype(str))
#
# # ç‰¹å¾µèˆ‡ç›®æ¨™æ¬„ä½
# features = ['å¹³å°', 'éŠæˆ²é¡å‹', 'ç™¼è¡Œå¹´ä»½', 'ç™¼è¡Œå•†']
# X = game[features].values
# y = game['ç¸½éŠ·å”®é¡'].values.reshape(-1, 1)
#
#
# # ç‰¹å¾µ/ç›®æ¨™æ¨™æº–åŒ–
# scaler_X = StandardScaler()
# scaler_y = StandardScaler()
# X_scaled = scaler_X.fit_transform(X)
# y_scaled = scaler_y.fit_transform(y)
#
#
# # è³‡æ–™åˆ‡åˆ†
# X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)
#
#
# from sklearn.linear_model import LogisticRegression
# from sklearn.neighbors import KNeighborsRegressor
# from sklearn.tree import DecisionTreeRegressor
# from sklearn.ensemble import RandomForestRegressor
# from sklearn.svm import SVR
# from xgboost import XGBRegressor
#
# models = {
#     'K-Nearest Neighbors': KNeighborsRegressor(n_neighbors=5),
#     'Decision Tree': DecisionTreeRegressor(random_state=42),
#     'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),
#     'SVM': SVR(kernel='rbf'),
#     'XGBoost': XGBRegressor(n_estimators=100, random_state=42)
# }
#
# print("\nğŸ” å„æ¨¡å‹é æ¸¬è¡¨ç¾ï¼š")
# for name, model in models.items():
#     model.fit(X_train, y_train.ravel())
#     y_pred = model.predict(X_test)
#
#     # åæ¨™æº–åŒ–
#     y_pred = scaler_y.inverse_transform(y_pred.reshape(-1, 1))
#     y_true = scaler_y.inverse_transform(y_test)
#
#     mse = mean_squared_error(y_true, y_pred)
#     r2 = r2_score(y_true, y_pred)
#     print(f"{name:<20} â¤ MSE: {mse:.2f}, RÂ²: {r2:.2f}")



features = ['å¹³å°', 'éŠæˆ²é¡å‹', 'ç™¼è¡Œå¹´ä»½', 'ç™¼è¡Œå•†']
target = ['ç¸½éŠ·å”®é¡']

mean_sales = game[target].mean()
game['Best_Seller'] = (game[target] > mean_sales).astype(int)

# é¡åˆ¥ç‰¹å¾µè½‰æ›
game = game[features + ['Best_Seller']].dropna()
label_cols = ['å¹³å°', 'éŠæˆ²é¡å‹', 'ç™¼è¡Œå•†']
for col in label_cols:
    game[col] = LabelEncoder().fit_transform(game[col].astype(str))

X = game[features]
y = game['Best_Seller']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# ç‰¹å¾µæ¨™æº–åŒ–ï¼ˆå°æŸäº›æ¨¡å‹æ•ˆæœæ›´å¥½ï¼‰
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from xgboost import XGBClassifier
from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import (
    confusion_matrix, accuracy_score, precision_score,
    recall_score, f1_score
)


# 6. å®šç¾©æ¨¡å‹å€‘
models = {
    'Logistic Regression': LogisticRegression(),
    'KNN': KNeighborsClassifier(n_neighbors=5),
    'Decision Tree': DecisionTreeClassifier(max_depth=5),
    'Random Forest': RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42),
    'SVM': SVC(kernel='rbf', probability = True),
    'XGBoost': XGBClassifier(n_estimators=100, random_state=42)
}


# æ¨¡å‹è©•ä¼°ï¼šæ··æ·†çŸ©é™£
plt.figure(figsize=(15, 10))
for i, (name, model) in enumerate(models.items()):
    model.fit(X_train_scaled, y_train)
    y_pred = model.predict(X_test_scaled)

    # æ··æ·†çŸ©é™£
    cm = confusion_matrix(y_test, y_pred)
    plt.subplot(2, 3, i + 1)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.title(f'{name}\nConfusion Matrix')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')

    # è¨ˆç®—æŒ‡æ¨™
    acc = accuracy_score(y_test, y_pred)
    prec = precision_score(y_test, y_pred, zero_division=0)
    rec = recall_score(y_test, y_pred, zero_division=0)
    f1 = f1_score(y_test, y_pred, zero_division=0)

    # é¡¯ç¤ºæŒ‡æ¨™ï¼ˆè¨»è§£åœ¨å­åœ–ä¸‹æ–¹ï¼‰
    plt.gca().text(0, -0.6,
                   f'Acc: {acc:.2f}\nPrec: {prec:.2f}\nRec: {rec:.2f}\nF1: {f1:.2f}',
                   fontsize=10, ha='left', transform=plt.gca().transAxes)
plt.tight_layout()
plt.show()

# ROC æ›²ç·š
# é¸æ“‡è¦è·‘çš„æ¨¡å‹
selected_models = {
    'KNN': KNeighborsClassifier(n_neighbors=5),
    'Decision Tree': DecisionTreeClassifier(max_depth=5),
    'XGBoost': XGBClassifier(n_estimators=100, random_state=42)
}
plt.figure(figsize=(10, 8))

for name, model in selected_models.items():
    model.fit(X_train_scaled, y_train)
    y_prob = model.predict_proba(X_test_scaled)[:, 1]  # é æ¸¬æ­£é¡æ©Ÿç‡
    fpr, tpr, _ = roc_curve(y_test, y_prob)
    auc = roc_auc_score(y_test, y_prob)

    plt.plot(fpr, tpr, label=f"{name} (AUC = {auc:.2f})")

plt.plot([0, 1], [0, 1], 'k--')  # åƒè€ƒç·š
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC æ›²ç·š')
plt.legend()
plt.grid()
plt.show()

# # æ¯å¹´éŠ·å”®é¡
# sales_by_year = game.groupby('ç™¼è¡Œå¹´ä»½', as_index=False)['ç¸½éŠ·å”®é¡'].sum()
#
# # æŠ˜ç·šåœ–ï¼šå¹´åº¦éŠ·å”®é¡
# plt.figure(figsize=(10, 5))
# sns.lineplot(data=sales_by_year, x='ç™¼è¡Œå¹´ä»½', y='ç¸½éŠ·å”®é¡', marker='o', color='black')
# plt.title("å¹´åº¦éŠ·å”®ç¸½é¡")
# plt.xlabel("å¹´ä»½")
# plt.ylabel("ç¸½éŠ·å”®é¡(ç™¾è¬)")
# plt.xticks(rotation=45)
# plt.tight_layout()
# plt.show()
#
# # ä¸åŒéŠæˆ²é¡å‹çš„éŠ·å”®æ•¸é‡
# type_count = game['éŠæˆ²é¡å‹'].value_counts().reset_index()
# type_count.columns = ['éŠæˆ²é¡å‹', 'æ•¸é‡']
#
# plt.figure(figsize=(10, 5))
# sns.barplot(data=type_count, x='éŠæˆ²é¡å‹', y='æ•¸é‡', color='darkgreen')
# for i, row in type_count.iterrows():
#     plt.text(i, row['æ•¸é‡'] + 10, row['æ•¸é‡'], ha='center', size=8)
# plt.title("éŠæˆ²é¡åˆ¥ç™¼å¸ƒæ•¸é‡")
# plt.xlabel("éŠæˆ²é¡åˆ¥")
# plt.ylabel("æ•¸é‡")
# plt.xticks(rotation=10)
# plt.tight_layout()
# plt.show()
#
# # ä¸åŒéŠæˆ²é¡å‹çš„éŠ·å”®é‡‘é¡
# type_sales = game.groupby('éŠæˆ²é¡å‹', as_index=False)['ç¸½éŠ·å”®é¡'].sum()
#
# plt.figure(figsize=(10, 5))
# sns.barplot(data=type_sales.sort_values('ç¸½éŠ·å”®é¡', ascending=False),
#             x='éŠæˆ²é¡å‹', y='ç¸½éŠ·å”®é¡', color='steelblue')
# for i, row in type_sales.sort_values('ç¸½éŠ·å”®é¡', ascending=False).iterrows():
#     plt.text(i, row['ç¸½éŠ·å”®é¡'] + 1, round(row['ç¸½éŠ·å”®é¡'], 1), ha='center', size=8)
# plt.title("éŠæˆ²é¡åˆ¥éŠ·å”®ç¸½é¡")
# plt.xlabel("éŠæˆ²é¡åˆ¥")
# plt.ylabel("éŠ·å”®é¡(ç™¾è¬)")
# plt.xticks(rotation=45)
# plt.tight_layout()
# plt.show()
#
# # ä¸åŒå¹³å°çš„éŠ·å”®é‡‘é¡
# platform_sales = game.groupby('å¹³å°', as_index=False)['ç¸½éŠ·å”®é¡'].sum()
#
# plt.figure(figsize=(10, 5))
# sns.barplot(data=platform_sales.sort_values('ç¸½éŠ·å”®é¡', ascending=False),
#             x='å¹³å°', y='ç¸½éŠ·å”®é¡', color='steelblue')
# for i, row in platform_sales.sort_values('ç¸½éŠ·å”®é¡', ascending=False).iterrows():
#     plt.text(i, row['ç¸½éŠ·å”®é¡'] + 1, round(row['ç¸½éŠ·å”®é¡'], 1), ha='center', size=8)
# plt.title("å¹³å°éŠ·å”®ç¸½é¡")
# plt.xlabel("å¹³å°")
# plt.ylabel("éŠ·å”®é¡(ç™¾è¬)")
# plt.xticks(rotation=45)
# plt.tight_layout()
# plt.show()
#
# # å¤šå¹³å°éŠæˆ²çµ±è¨ˆ
# duplicate_games = game.groupby('éŠæˆ²åç¨±')['å¹³å°'].nunique().reset_index()
# duplicate_games = duplicate_games[duplicate_games['å¹³å°'] > 1]
#
# multi_platform_games = game[game['éŠæˆ²åç¨±'].isin(duplicate_games['éŠæˆ²åç¨±'])] \
#     .sort_values(by=['éŠæˆ²åç¨±', 'å¹³å°'])
#
# print(multi_platform_games)
#
# # ç™¼è¡Œå•†éŠ·å”®é‡‘é¡å‰ 10 å
# publisher_sales = game.groupby('ç™¼è¡Œå•†', as_index=False)['ç¸½éŠ·å”®é¡'].sum()
# top10_publishers = publisher_sales.sort_values('ç¸½éŠ·å”®é¡', ascending=False).head(10)
#
# plt.figure(figsize=(10, 5))
# sns.barplot(data=top10_publishers, x='ç™¼è¡Œå•†', y='ç¸½éŠ·å”®é¡', color='steelblue')
# for i, row in top10_publishers.iterrows():
#     plt.text(i, row['ç¸½éŠ·å”®é¡'] + 1, round(row['ç¸½éŠ·å”®é¡'], 1), ha='center', size=8)
# plt.title("ç™¼è¡Œå•†éŠ·å”®ç¸½é¡")
# plt.xlabel("ç™¼è¡Œå•†")
# plt.ylabel("éŠ·å”®é¡(ç™¾è¬)")
# plt.xticks(rotation=45)
# plt.tight_layout()
# plt.show()
#
# # åœ°å€èˆ‡éŠæˆ²é¡å‹æ¯”ä¾‹ï¼ˆé•·è³‡æ–™æ ¼å¼ï¼‰
# df_long = game.melt(
#     id_vars=['éŠæˆ²é¡å‹'],
#     value_vars=['åŒ—ç¾éŠ·å”®é¡', 'æ­æ´²éŠ·å”®é¡', 'æ—¥æœ¬éŠ·å”®é¡', 'å…¶ä»–åœ°å€éŠ·å”®é¡'],
#     var_name='Region',
#     value_name='Sales'
# )
#
# region_grouped = df_long.groupby(['Region', 'éŠæˆ²é¡å‹'], as_index=False)['Sales'].sum()
# region_grouped['Percentage'] = region_grouped.groupby('Region')['Sales'].apply(lambda x: 100 * x / x.sum())
#
# top_labels = region_grouped.loc[region_grouped.groupby('Region')['Percentage'].idxmax()]
#
# # ç¹ªè£½æ¥µåæ¨™åœ–ï¼ˆpie charts ä½¿ç”¨ subplot + polarï¼‰
# import plotly.express as px
#
# fig = px.sunburst(
#     region_grouped,
#     path=['Region', 'éŠæˆ²é¡å‹'],
#     values='Sales',
#     color='éŠæˆ²é¡å‹',
#     title='å„åœ°å€ä¸åŒéŠæˆ²é¡å‹éŠ·å”®æ¯”ä¾‹'
# )
# fig.show()

